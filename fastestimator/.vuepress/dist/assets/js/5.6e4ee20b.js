(window.webpackJsonp=window.webpackJsonp||[]).push([[5],{189:function(e,a,t){"use strict";t.r(a);var r=t(0),s=Object(r.a)({},function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"fastestimator-api-reference"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fastestimator-api-reference","aria-hidden":"true"}},[e._v("#")]),e._v(" FastEstimator API reference")]),e._v(" "),t("h2",{attrs:{id:"pipeline"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pipeline","aria-hidden":"true"}},[e._v("#")]),e._v(" Pipeline")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-pipeline-pipeline-batch-size-feature-name-transform-train-transform-dataset-none-train-data-none-validation-data-none-data-filter-none-shuffle-buffer-auto-kwargs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-pipeline-pipeline-batch-size-feature-name-transform-train-transform-dataset-none-train-data-none-validation-data-none-data-filter-none-shuffle-buffer-auto-kwargs","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.pipeline.Pipeline(batch_size, feature_name, transform_train, transform_dataset=None, train_data=None, validation_data=None, data_filter=None, shuffle_buffer='auto', **kwargs)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("Class representing the data pipeline required for fastestimator")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("batch_size")]),e._v(" – Integer representing the batch size for training model")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature_name")]),e._v(" – List of strings representing the feature names in the data (headers in csv, keys in dictionary\nor features in TFRecords)")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("transform_train")]),e._v(" – List of lists of tensor transformations to be performed sequentially on the corresponding\nfeatures.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("transform_dataset")]),e._v(" – List of lists of numpy transformations to be performed sequentially  on the raw data\nbefore the TFRecords are made.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("train_data")]),e._v(" – Training dataset in the form of dictionary containing numpy data, or csv file (with file\npaths or data)")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("validation_data")]),e._v(" – Validation data in the form of dictionary containing numpy data, or csv file, or fraction\nof training data to be sequestered for validation during training")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("data_filter")]),e._v(" – Filtering to be performed on the corresponding features in the form of an object from the Filter class")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("shuffle_buffer")]),e._v(" – buffer size for the shuffling, it can affect the memory consumption during training. default is ‘auto’.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("**kwargs")]),e._v(" – Additional arguments to be forwarded for the creation of TFRecords.")])])])])]),e._v(" "),t("h4",{attrs:{id:"edit-feature-feature"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#edit-feature-feature","aria-hidden":"true"}},[e._v("#")]),e._v(" edit_feature(feature)")]),e._v(" "),t("p",[e._v("Can be overloaded to change raw data dictionary in any manner")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("feature")]),e._v(" – Dictionary containing the raw data")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Dictionary containing raw data to be stored in TFRecords")])])]),e._v(" "),t("h4",{attrs:{id:"final-transform-preprocessed-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#final-transform-preprocessed-data","aria-hidden":"true"}},[e._v("#")]),e._v(" final_transform(preprocessed_data)")]),e._v(" "),t("p",[e._v("Can be overloaded to change tensors in any manner")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("preprocessed_data")]),e._v(" – Batch of training data as a tf.data object")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("A dictionary of tensor data in the form of a tf.data object.")])])]),e._v(" "),t("h4",{attrs:{id:"read-and-decode-dataset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#read-and-decode-dataset","aria-hidden":"true"}},[e._v("#")]),e._v(" read_and_decode(dataset)")]),e._v(" "),t("p",[e._v("Reads and decodes the string data from TFRecords")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("dataset")]),e._v(" – Dataset consisting of encoded data from TFRecords")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Dictionary of decoded data")])])]),e._v(" "),t("h4",{attrs:{id:"show-batches-mode-train-inputs-none-num-batches-1"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#show-batches-mode-train-inputs-none-num-batches-1","aria-hidden":"true"}},[e._v("#")]),e._v(" show_batches(mode='train', inputs=None, num_batches=1)")]),e._v(" "),t("p",[e._v("Shows batches of tensor data in numpy")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("mode")]),e._v(" – Mode for training (“train”, “eval” or “both”)")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("inputs")]),e._v(" – Directory for saving TFRecords")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("num_batches")]),e._v(" – Number of batches to show")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("A dictionary containing the batches numpy data with corresponding keys")])])]),e._v(" "),t("h2",{attrs:{id:"dynamic-preprocess"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dynamic-preprocess","aria-hidden":"true"}},[e._v("#")]),e._v(" Dynamic Preprocess")]),e._v(" "),t("h3",{attrs:{id:"abstractpreprocessing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#abstractpreprocessing","aria-hidden":"true"}},[e._v("#")]),e._v(" AbstractPreprocessing")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-abstractpreprocessing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-abstractpreprocessing","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing()")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("An abstract class for preprocessing")]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Placeholder function that is to be inherited by preprocessing classes.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be preprocessed")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary decoded data needed for the preprocessing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed data numpy array")])])]),e._v(" "),t("h3",{attrs:{id:"nrrdreader"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#nrrdreader","aria-hidden":"true"}},[e._v("#")]),e._v(" NrrdReader")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-nrrdreader-parent-path"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-nrrdreader-parent-path","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.NrrdReader(parent_path='')")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Class for reading NRRD images")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("parent_path")]),e._v(" ("),t("em",[e._v("str")]),e._v(") – Parent path that will be added on given path.")])])]),e._v(" "),t("h4",{attrs:{id:"transform-path-feature-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-path-feature-none","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(path, feature=None)")]),e._v(" "),t("p",[e._v("Reads from NRRD image path")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("path")]),e._v(" – path of the NRRD image")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data that may be used by the image reader")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Image as numpy array")])])]),e._v(" "),t("h3",{attrs:{id:"imagereader"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#imagereader","aria-hidden":"true"}},[e._v("#")]),e._v(" ImageReader")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-imagereader-parent-path-grey-scale-false"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-imagereader-parent-path-grey-scale-false","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.ImageReader(parent_path='', grey_scale=False)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Class for reading png or jpg images")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("parent_path")]),e._v(" – Parent path that will be added on given path")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("grey_scale")]),e._v(" – Boolean to indicate whether or not to read image as grayscale")])])])])]),e._v(" "),t("h4",{attrs:{id:"transform-path-feature-none-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-path-feature-none-2","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(path, feature=None)")]),e._v(" "),t("p",[e._v("Reads numpy array from image path")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("path")]),e._v(" – path of the image")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data that may be used by the image reader")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Image as numpy array")])])]),e._v(" "),t("h3",{attrs:{id:"zscore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zscore","aria-hidden":"true"}},[e._v("#")]),e._v(" Zscore")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-zscore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-zscore","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.Zscore()")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Standardize data using zscore method")]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none-2","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Standardizes the data")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be standardized")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data needed for the standardization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Array containing standardized data")])])]),e._v(" "),t("h3",{attrs:{id:"minmax"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#minmax","aria-hidden":"true"}},[e._v("#")]),e._v(" Minmax")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-minmax"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-minmax","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.Minmax()")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Normalize data using the minmax method")]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none-3","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Normalizes the data")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be normalized")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data needed for the normalization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Normalized numpy array")])])]),e._v(" "),t("h3",{attrs:{id:"scale"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scale","aria-hidden":"true"}},[e._v("#")]),e._v(" Scale")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-scale-scalar"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-scale-scalar","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.Scale(scalar)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for scaling dataset")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("scalar")]),e._v(" – Scalar for scaling the data")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none-4"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none-4","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Scales the data tensor")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be scaled")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data needed for the normalization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Scaled data array")])])]),e._v(" "),t("h3",{attrs:{id:"onehot"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#onehot","aria-hidden":"true"}},[e._v("#")]),e._v(" Onehot")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-onehot-num-dim"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-onehot-num-dim","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.Onehot(num_dim)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for converting categorical labels to onehot encoding")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("num_dim")]),e._v(" – Number of dimensions of the labels")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none-5"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none-5","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Transforms categorical labels to onehot encodings")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be preprocessed")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data needed for the preprocessing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed labels")])])]),e._v(" "),t("h3",{attrs:{id:"resize"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#resize","aria-hidden":"true"}},[e._v("#")]),e._v(" Resize")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-resize-size-resize-method-bilinear"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-resize-size-resize-method-bilinear","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.Resize(size, resize_method='bilinear')")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none-6"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none-6","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Placeholder function that is to be inherited by preprocessing classes.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be preprocessed")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary decoded data needed for the preprocessing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed data numpy array")])])]),e._v(" "),t("h3",{attrs:{id:"reshape"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reshape","aria-hidden":"true"}},[e._v("#")]),e._v(" Reshape")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-dynamic-preprocess-reshape-shape"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-dynamic-preprocess-reshape-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.dynamic.preprocess.Reshape(shape)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.dynamic.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for reshaping the data")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("shape")]),e._v(" – target shape")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-feature-none-7"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-feature-none-7","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, feature=None)")]),e._v(" "),t("p",[e._v("Reshapes data array")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be reshaped")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature")]),e._v(" – Auxiliary data needed for the resizing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Reshaped array")])])]),e._v(" "),t("h2",{attrs:{id:"static-preprocess"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#static-preprocess","aria-hidden":"true"}},[e._v("#")]),e._v(" Static Preprocess")]),e._v(" "),t("h3",{attrs:{id:"abstractpreprocessing-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#abstractpreprocessing-2","aria-hidden":"true"}},[e._v("#")]),e._v(" AbstractPreprocessing")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-abstractpreprocessing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-abstractpreprocessing","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.AbstractPreprocessing()")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("An abstract class for preprocessing")]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Placeholder function that is to be inherited by preprocessing classes.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be preprocessed")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the preprocessing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed data tensor")])])]),e._v(" "),t("h3",{attrs:{id:"binarize"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#binarize","aria-hidden":"true"}},[e._v("#")]),e._v(" Binarize")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-binarize-threshold"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-binarize-threshold","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Binarize(threshold)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Binarize data based on threshold between 0 and 1")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("threshold")]),e._v(" – Threshold for binarizing")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-2","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Transforms the image to binary based on threshold")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be binarized")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the binarization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Tensor containing binarized data")])])]),e._v(" "),t("h3",{attrs:{id:"zscore-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zscore-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Zscore")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-zscore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-zscore","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Zscore()")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Standardize data using zscore method")]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-3","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Standardizes the data tensor")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be standardized")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the standardization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Tensor containing standardized data")])])]),e._v(" "),t("h3",{attrs:{id:"minmax-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#minmax-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Minmax")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-minmax"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-minmax","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Minmax()")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Normalize data using the minmax method")]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-4"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-4","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Normalizes the data tensor")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be normalized")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the normalization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Tensor after minmax")])])]),e._v(" "),t("h3",{attrs:{id:"scale-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scale-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Scale")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-scale-scalar"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-scale-scalar","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Scale(scalar)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for scaling dataset")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("scalar")]),e._v(" – Scalar for scaling the data")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-5"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-5","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Scales the data tensor")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be scaled")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the normalization")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Scaled data tensor")])])]),e._v(" "),t("h3",{attrs:{id:"onehot-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#onehot-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Onehot")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-onehot-num-dim"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-onehot-num-dim","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Onehot(num_dim)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for converting categorical labels to onehot encoding")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("num_dim")]),e._v(" – Number of dimensions of the labels")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-6"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-6","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Transforms categorical labels to onehot encodings")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be preprocessed")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the preprocessing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed labels")])])]),e._v(" "),t("h3",{attrs:{id:"resize-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#resize-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Resize")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-resize-size-resize-method-0"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-resize-size-resize-method-0","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Resize(size, resize_method=0)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for resizing the images")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("size")]),e._v(" – Destination shape of the images")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("resize_method")]),e._v(" – One of resize methods provided by tensorflow to be used")])])])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-7"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-7","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Resizes data tensor")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Tensor to be resized")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the resizing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Resized tensor")])])]),e._v(" "),t("h3",{attrs:{id:"reshape-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reshape-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Reshape")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-preprocess-reshape-shape"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-preprocess-reshape-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.preprocess.Reshape(shape)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.preprocess.AbstractPreprocessing")])]),e._v(" "),t("p",[e._v("Preprocessing class for reshaping the data")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("shape")]),e._v(" – target shape")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-decoded-data-none-8"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-decoded-data-none-8","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data, decoded_data=None)")]),e._v(" "),t("p",[e._v("Reshapes data tensor")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data")]),e._v(" – Data to be reshaped")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decoded_data")]),e._v(" – Auxiliary decoded data needed for the resizing")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Reshaped tensor")])])]),e._v(" "),t("h2",{attrs:{id:"augmentation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#augmentation","aria-hidden":"true"}},[e._v("#")]),e._v(" Augmentation")]),e._v(" "),t("h3",{attrs:{id:"abstractaugmentation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#abstractaugmentation","aria-hidden":"true"}},[e._v("#")]),e._v(" AbstractAugmentation")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-augmentation-abstractaugmentation-mode-train"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-augmentation-abstractaugmentation-mode-train","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.augmentation.AbstractAugmentation(mode='train')")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("An abstract class for data augmentation that defines interfaces.\nA custom augmentation can be defined by inheriting from this class.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("mode")]),e._v(" – Augmentation to be applied for training or evaluation, can be “train”, “eval” or “both”.")])])]),e._v(" "),t("h4",{attrs:{id:"setup"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#setup","aria-hidden":"true"}},[e._v("#")]),e._v(" setup()")]),e._v(" "),t("p",[e._v("An interface method to be implemented by inheriting augmentation class to setup necessary parameters for the\naugmentation")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("None")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data)")]),e._v(" "),t("p",[e._v("An interface method to be implemented by inheriting augmentation class to apply the transformation to data")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("data")]),e._v(" – Data on which a transformation is to be applied")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed tensor")])])]),e._v(" "),t("h3",{attrs:{id:"augmentation-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#augmentation-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Augmentation")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-augmentation-augmentation-rotation-range-0-0-width-shift-range-0-0-height-shift-range-0-0-shear-range-0-0-zoom-range-1-0-flip-left-right-false-flip-up-down-false-mode-train"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-augmentation-augmentation-rotation-range-0-0-width-shift-range-0-0-height-shift-range-0-0-shear-range-0-0-zoom-range-1-0-flip-left-right-false-flip-up-down-false-mode-train","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.augmentation.Augmentation(rotation_range=0.0, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.0, zoom_range=1.0, flip_left_right=False, flip_up_down=False, mode='train')")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("fastestimator.pipeline.static.augmentation.AbstractAugmentation")])]),e._v(" "),t("p",[e._v("This class supports commonly used 2D random affine transformations for data augmentation.\nEither a scalar "),t("code",[e._v("x")]),e._v(" or a tuple "),t("code",[e._v("[x1, x2]")]),e._v(" can be specified for rotation, shearing, shifting, and zoom.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("rotation_range")]),e._v(" – Scalar (x) that represents the range of random rotation (in degrees) from -x to x /\nTuple ([x1, x2]) that represents  the range of random rotation between x1 and x2.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("width_shift_range")]),e._v(" – Float (x) that represents the range of random width shift (in pixels) from -x to x /\nTuple ([x1, x2]) that represents  the range of random width shift between x1 and x2.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("height_shift_range")]),e._v(" – Float (x) that represents the range of random height shift (in pixels) from -x to x /\nTuple ([x1, x2]) that represents  the range of random height shift between x1 and x2.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("shear_range")]),e._v(" – Scalar (x) that represents the range of random shear (in degrees) from -x to x /\nTuple ([x1, x2]) that represents  the range of random shear between x1 and x2.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("zoom_range")]),e._v(" – Float (x) that represents the range of random zoom (in percentage) from -x to x /\nTuple ([x1, x2]) that represents  the range of random zoom between x1 and x2.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("flip_left_right")]),e._v(" – Boolean representing whether to flip the image horizontally with a probability of 0.5.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("flip_up_down")]),e._v(" – Boolean representing whether to flip the image vertically with a probability of 0.5.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("mode")]),e._v(" – Augmentation on ‘training’ data or ‘evaluation’ data.")])])])])]),e._v(" "),t("h4",{attrs:{id:"flip"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flip","aria-hidden":"true"}},[e._v("#")]),e._v(" flip()")]),e._v(" "),t("p",[e._v("Decides whether or not to flip")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("A boolean that represents whether or not to flip")])])]),e._v(" "),t("h4",{attrs:{id:"rotate"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rotate","aria-hidden":"true"}},[e._v("#")]),e._v(" rotate()")]),e._v(" "),t("p",[e._v("Creates affine transformation matrix for 2D rotation")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transform affine tensor")])])]),e._v(" "),t("h4",{attrs:{id:"setup-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#setup-2","aria-hidden":"true"}},[e._v("#")]),e._v(" setup()")]),e._v(" "),t("p",[e._v("This method set the appropriate variables necessary for the random 2D augmentation. It also computes the\ntransformation matrix.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("None")])])]),e._v(" "),t("h4",{attrs:{id:"shear"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#shear","aria-hidden":"true"}},[e._v("#")]),e._v(" shear()")]),e._v(" "),t("p",[e._v("Creates affine transformation matrix for 2D shear")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transform affine tensor")])])]),e._v(" "),t("h4",{attrs:{id:"shift"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#shift","aria-hidden":"true"}},[e._v("#")]),e._v(" shift()")]),e._v(" "),t("p",[e._v("Creates affine transformation matrix for 2D shift")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transform affine tensor")])])]),e._v(" "),t("h4",{attrs:{id:"transform-data-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-data-2","aria-hidden":"true"}},[e._v("#")]),e._v(" transform(data)")]),e._v(" "),t("p",[e._v("Transforms the data with the augmentation transformation")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("data")]),e._v(" – Data to be transformed")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transformed (augmented) data")])])]),e._v(" "),t("h4",{attrs:{id:"transform-matrix-offset-center-matrix"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transform-matrix-offset-center-matrix","aria-hidden":"true"}},[e._v("#")]),e._v(" transform_matrix_offset_center(matrix)")]),e._v(" "),t("p",[e._v("Offsets the tensor to the center of the image")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("matrix")]),e._v(" – Affine tensor")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("An affine tensor offset to the center of the image")])])]),e._v(" "),t("h4",{attrs:{id:"zoom"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zoom","aria-hidden":"true"}},[e._v("#")]),e._v(" zoom()")]),e._v(" "),t("p",[e._v("Creates affine transformation matrix for 2D zoom / scale")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Transform affine tensor")])])]),e._v(" "),t("h2",{attrs:{id:"filter"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#filter","aria-hidden":"true"}},[e._v("#")]),e._v(" Filter")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-pipeline-static-filter-filter-feature-name-filter-value-keep-prob-mode-train"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-pipeline-static-filter-filter-feature-name-filter-value-keep-prob-mode-train","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.pipeline.static.filter.Filter(feature_name, filter_value, keep_prob, mode='train')")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("Class for performing filtering on dataset based on scalar values.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("feature_name")]),e._v(" – Name of the key in the dataset that is to be filtered")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("filter_value")]),e._v(" – The values in the dataset that are to be filtered.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("keep_prob")]),e._v(" – The probability of keeping the example")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("mode")]),e._v(" – filter on ‘train’, ‘eval’ or ‘both’")])])])])]),e._v(" "),t("h4",{attrs:{id:"predicate-fn-dataset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#predicate-fn-dataset","aria-hidden":"true"}},[e._v("#")]),e._v(" predicate_fn(dataset)")]),e._v(" "),t("p",[e._v("Filters the dataset based on the filter probabilities.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("dataset")]),e._v(" – Tensorflow dataset object which is to be filtered")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Tensorflow conditional for filtering the dataset based on the probabilities for each of the values.")])])]),e._v(" "),t("h2",{attrs:{id:"cyclic-learning-rate"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cyclic-learning-rate","aria-hidden":"true"}},[e._v("#")]),e._v(" Cyclic Learning Rate")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-network-lrscheduler-cyclicscheduler-num-cycle-1-cycle-multiplier-2-decrease-method-cosine"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-network-lrscheduler-cyclicscheduler-num-cycle-1-cycle-multiplier-2-decrease-method-cosine","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.network.lrscheduler.CyclicScheduler(num_cycle=1, cycle_multiplier=2, decrease_method='cosine')")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("A class representing cyclic learning rate scheduler")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("num_cycle")]),e._v(" – The number of cycles to be used by the learning rate scheduler")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("cycle_multiplier")]),e._v(" – The length of each next cycle’s multiplier")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("decrease_method")]),e._v(" – The decay method to be used with cyclic learning rate scheduler")])])])])]),e._v(" "),t("h4",{attrs:{id:"lr-cosine-decay-global-steps-lr-ratio-start-lr-ratio-end-step-start-step-end"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lr-cosine-decay-global-steps-lr-ratio-start-lr-ratio-end-step-start-step-end","aria-hidden":"true"}},[e._v("#")]),e._v(" lr_cosine_decay(global_steps, lr_ratio_start, lr_ratio_end, step_start, step_end)")]),e._v(" "),t("h4",{attrs:{id:"lr-linear-decay-global-steps-lr-ratio-start-lr-ratio-end-step-start-step-end"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lr-linear-decay-global-steps-lr-ratio-start-lr-ratio-end-step-start-step-end","aria-hidden":"true"}},[e._v("#")]),e._v(" lr_linear_decay(global_steps, lr_ratio_start, lr_ratio_end, step_start, step_end)")]),e._v(" "),t("h4",{attrs:{id:"lr-schedule-fn-global-steps"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lr-schedule-fn-global-steps","aria-hidden":"true"}},[e._v("#")]),e._v(" lr_schedule_fn(global_steps)")]),e._v(" "),t("p",[e._v("The actual function that computes the learning rate decay ratio using cyclic learning rate.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("global_steps")]),e._v(" – Current global step")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Learning rate ratio")])])]),e._v(" "),t("h2",{attrs:{id:"network"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#network","aria-hidden":"true"}},[e._v("#")]),e._v(" Network")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-network-network-network-model-loss-metrics-none-loss-weights-none-optimizer-adam-model-dir-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-network-network-network-model-loss-metrics-none-loss-weights-none-optimizer-adam-model-dir-none","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.network.network.Network(model, loss, metrics=None, loss_weights=None, optimizer='adam', model_dir=None)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("Class for representing the model for fastestimator")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("model")]),e._v(" – An instance of tensorflow.keras model object.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("loss")]),e._v(" – String or list or dictionary of strings representing a loss function (defined in keras)\nor it can be a function handle of a customized loss function that takes a true value and\npredicted value and returns a scalar loss value.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("metrics")]),e._v(" – List or dictionary of strings representing metrics (defined in keras)\nor it can be a list of function handles of a customized metric function that\ntakes a true values and predicted values and returns a scalar metric.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("loss_weights")]),e._v(" – List of floats used only if the loss is a weighted loss\nwith the individual components defined as a list in the “loss member variable” (default: "),t("code",[e._v("None")]),e._v(")")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("optimizer")]),e._v(" – the type the optimizer for the model in the form of a string.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("model_dir")]),e._v(" – Directory where the model is to be saved (default is the temporary directory)")])])])])]),e._v(" "),t("h2",{attrs:{id:"estimator"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#estimator","aria-hidden":"true"}},[e._v("#")]),e._v(" Estimator")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-estimator-estimator-estimator-pipeline-network-epochs-steps-per-epoch-none-validation-steps-none-callbacks-log-steps-100"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-estimator-estimator-estimator-pipeline-network-epochs-steps-per-epoch-none-validation-steps-none-callbacks-log-steps-100","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.estimator.estimator.Estimator(pipeline, network, epochs, steps_per_epoch=None, validation_steps=None, callbacks=[], log_steps=100)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[t("code",[e._v("Estimator")]),e._v(" class compiles all the components necessary to train a model.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("pipeline")]),e._v(" – Object of the Pipeline class that consists of data parameters.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("network")]),e._v(" – Object of the Network class that consists of the model definition and parameters.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("epochs")]),e._v(" – Total number of training epochs")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("steps_per_epoch")]),e._v(" – The number batches in one epoch of training,\nif None, it will be automatically calculated. Evaluation is performed at the end of every epoch.\n(default: "),t("code",[e._v("None")]),e._v(")")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("validation_steps")]),e._v(" – Number of batches to be used for validation")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("callbacks")]),e._v(" – List of callbacks object in tf.keras. (default: "),t("code",[e._v("[]")]),e._v(")")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("log_steps")]),e._v(" – Number of steps after which training logs will be displayed periodically.")])])])])]),e._v(" "),t("h4",{attrs:{id:"fit-inputs-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fit-inputs-none","aria-hidden":"true"}},[e._v("#")]),e._v(" fit(inputs=None)")]),e._v(" "),t("p",[e._v("Function to perform training on the estimator")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("inputs")]),e._v(" – Path to input data")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("None")])])]),e._v(" "),t("h4",{attrs:{id:"train"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#train","aria-hidden":"true"}},[e._v("#")]),e._v(" train()")]),e._v(" "),t("h2",{attrs:{id:"callbacks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#callbacks","aria-hidden":"true"}},[e._v("#")]),e._v(" Callbacks")]),e._v(" "),t("h3",{attrs:{id:"outputlogger"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#outputlogger","aria-hidden":"true"}},[e._v("#")]),e._v(" OutputLogger")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-estimator-callbacks-outputlogger-batch-size-log-steps-100-validation-true-num-process-1"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-estimator-callbacks-outputlogger-batch-size-log-steps-100-validation-true-num-process-1","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.estimator.callbacks.OutputLogger(batch_size, log_steps=100, validation=True, num_process=1)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("tensorflow.python.keras.callbacks.Callback")])]),e._v(" "),t("p",[e._v("Keras callback for logging the output")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("batch_size")]),e._v(" – Size of the training batch")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("log_steps")]),e._v(" – Number of steps at which to output the logs")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("validation")]),e._v(" – Boolean representing whether or not to output validation information")])])])])]),e._v(" "),t("h4",{attrs:{id:"on-batch-begin-batch-logs-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-batch-begin-batch-logs-none","aria-hidden":"true"}},[e._v("#")]),e._v(" on_batch_begin(batch, logs=None)")]),e._v(" "),t("p",[e._v("A backwards compatibility alias for on_train_batch_begin.")]),e._v(" "),t("h4",{attrs:{id:"on-batch-end-batch-logs-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-batch-end-batch-logs-none","aria-hidden":"true"}},[e._v("#")]),e._v(" on_batch_end(batch, logs=None)")]),e._v(" "),t("p",[e._v("A backwards compatibility alias for on_train_batch_end.")]),e._v(" "),t("h4",{attrs:{id:"on-epoch-end-epoch-logs-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-epoch-end-epoch-logs-none","aria-hidden":"true"}},[e._v("#")]),e._v(" on_epoch_end(epoch, logs=None)")]),e._v(" "),t("p",[e._v("Called at the end of an epoch.")]),e._v(" "),t("p",[e._v("Subclasses should override for any actions to run. This function should only\nbe called during TRAIN mode.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("epoch")]),e._v(" – integer, index of epoch.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("logs")]),e._v(" – dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result keys\nare prefixed with val_.")])])])])]),e._v(" "),t("h3",{attrs:{id:"learningrateupdater"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#learningrateupdater","aria-hidden":"true"}},[e._v("#")]),e._v(" LearningRateUpdater")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-estimator-callbacks-learningrateupdater-init-lr"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-estimator-callbacks-learningrateupdater-init-lr","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.estimator.callbacks.LearningRateUpdater(init_lr)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("tensorflow.python.keras.callbacks.Callback")])]),e._v(" "),t("p",[e._v("Keras callback to update the learning rate")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("init_lr")]),e._v(" – initial learning rate")])])]),e._v(" "),t("h4",{attrs:{id:"on-batch-begin-batch-logs-none-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-batch-begin-batch-logs-none-2","aria-hidden":"true"}},[e._v("#")]),e._v(" on_batch_begin(batch, logs=None)")]),e._v(" "),t("p",[e._v("A backwards compatibility alias for on_train_batch_begin.")]),e._v(" "),t("h4",{attrs:{id:"on-batch-end-batch-logs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-batch-end-batch-logs","aria-hidden":"true"}},[e._v("#")]),e._v(" on_batch_end(batch, logs={})")]),e._v(" "),t("p",[e._v("A backwards compatibility alias for on_train_batch_end.")]),e._v(" "),t("h3",{attrs:{id:"learningratescheduler"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#learningratescheduler","aria-hidden":"true"}},[e._v("#")]),e._v(" LearningRateScheduler")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-estimator-callbacks-learningratescheduler-schedule"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-estimator-callbacks-learningratescheduler-schedule","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.estimator.callbacks.LearningRateScheduler(schedule)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("tensorflow.python.keras.callbacks.Callback")])]),e._v(" "),t("p",[e._v("Keras callback for the learning rate scheduler")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("schedule")]),e._v(" – Schedule object to passed to the scheduler")])])]),e._v(" "),t("h4",{attrs:{id:"on-batch-begin-batch-logs-none-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-batch-begin-batch-logs-none-3","aria-hidden":"true"}},[e._v("#")]),e._v(" on_batch_begin(batch, logs=None)")]),e._v(" "),t("p",[e._v("A backwards compatibility alias for on_train_batch_begin.")]),e._v(" "),t("h4",{attrs:{id:"on-epoch-begin-epoch-logs-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-epoch-begin-epoch-logs-none","aria-hidden":"true"}},[e._v("#")]),e._v(" on_epoch_begin(epoch, logs=None)")]),e._v(" "),t("p",[e._v("Called at the start of an epoch.")]),e._v(" "),t("p",[e._v("Subclasses should override for any actions to run. This function should only\nbe called during TRAIN mode.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("epoch")]),e._v(" – integer, index of epoch.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("logs")]),e._v(" – dict. Currently no data is passed to this argument for this method\nbut that may change in the future.")])])])])]),e._v(" "),t("h3",{attrs:{id:"reducelronplateau"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reducelronplateau","aria-hidden":"true"}},[e._v("#")]),e._v(" ReduceLROnPlateau")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-estimator-callbacks-reducelronplateau-monitor-val-loss-factor-0-1-patience-10-verbose-0-mode-auto-min-delta-0-0001-cooldown-0-kwargs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-estimator-callbacks-reducelronplateau-monitor-val-loss-factor-0-1-patience-10-verbose-0-mode-auto-min-delta-0-0001-cooldown-0-kwargs","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.estimator.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, **kwargs)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("tensorflow.python.keras.callbacks.Callback")])]),e._v(" "),t("p",[e._v("Keras callback for the reduce learning rate on pleateau")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("monitor")]),e._v(" – Metric to be monitored")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("factor")]),e._v(" – Factor by which to reduce learning rate")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("patience")]),e._v(" – Number of epochs to wait before reducing LR")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("verbose")]),e._v(" – Whether or not to output verbose logs")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("mode")]),e._v(" – Learning rate reduction mode")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("min_delta")]),e._v(" – Minimum significant difference")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("cooldown")]),e._v(" –")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("**kwargs")]),e._v(" –")])])])])]),e._v(" "),t("h4",{attrs:{id:"in-cooldown"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in-cooldown","aria-hidden":"true"}},[e._v("#")]),e._v(" in_cooldown()")]),e._v(" "),t("h4",{attrs:{id:"on-epoch-end-epoch-logs-none-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-epoch-end-epoch-logs-none-2","aria-hidden":"true"}},[e._v("#")]),e._v(" on_epoch_end(epoch, logs=None)")]),e._v(" "),t("p",[e._v("Called at the end of an epoch.")]),e._v(" "),t("p",[e._v("Subclasses should override for any actions to run. This function should only\nbe called during TRAIN mode.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("epoch")]),e._v(" – integer, index of epoch.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("logs")]),e._v(" – dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result keys\nare prefixed with val_.")])])])])]),e._v(" "),t("h4",{attrs:{id:"on-train-begin-logs-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#on-train-begin-logs-none","aria-hidden":"true"}},[e._v("#")]),e._v(" on_train_begin(logs=None)")]),e._v(" "),t("p",[e._v("Called at the beginning of training.")]),e._v(" "),t("p",[e._v("Subclasses should override for any actions to run.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("logs")]),e._v(" – dict. Currently no data is passed to this argument for this method\nbut that may change in the future.")])])]),e._v(" "),t("h2",{attrs:{id:"tfrecord-utility-functions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tfrecord-utility-functions","aria-hidden":"true"}},[e._v("#")]),e._v(" TFRecord Utility Functions")]),e._v(" "),t("h3",{attrs:{id:"tfrecorder"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tfrecorder","aria-hidden":"true"}},[e._v("#")]),e._v(" TFRecorder")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-util-tfrecord-tfrecorder-train-data-feature-name-transform-dataset-none-validation-data-none-create-patch-false-max-tfrecord-mb-300-compression-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-util-tfrecord-tfrecorder-train-data-feature-name-transform-dataset-none-validation-data-none-create-patch-false-max-tfrecord-mb-300-compression-none","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.util.tfrecord.TFRecorder(train_data, feature_name, transform_dataset=None, validation_data=None, create_patch=False, max_tfrecord_mb=300, compression=None)")]),e._v(" "),t("p",[e._v("Bases: "),t("code",[e._v("object")])]),e._v(" "),t("p",[e._v("Class for creating TFRecords from numpy data or csv file containing paths to data on disk")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("train_data")]),e._v(" – Training dataset in the form of dictionary containing numpy data, or csv file (with file\npaths or data)")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature_name")]),e._v(" – List of strings representing the feature names in the data (headers in csv, keys in dictionary\nor features in TFRecords)")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("transform_dataset")]),e._v(" – List of lists of numpy transformations to be performed sequentially  on the raw data\nbefore the TFRecords are made.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("validation_data")]),e._v(" – Validation data in the form of dictionary containing numpy data, or csv file, or fraction\nof training data to be sequestered for validation during training.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("create_patch")]),e._v(" – Whether to create multiple records from single example.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("max_tfrecord_mb")]),e._v(" – Maximum space to be occupied by one TFRecord.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("compression")]),e._v(" – tfrecords compression type, one of None, ‘GZIP’ or ‘ZLIB’.")])])])])]),e._v(" "),t("h4",{attrs:{id:"create-tfrecord-save-dir-none"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#create-tfrecord-save-dir-none","aria-hidden":"true"}},[e._v("#")]),e._v(" create_tfrecord(save_dir=None)")]),e._v(" "),t("h4",{attrs:{id:"edit-feature-feature-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#edit-feature-feature-2","aria-hidden":"true"}},[e._v("#")]),e._v(" edit_feature(feature)")]),e._v(" "),t("h3",{attrs:{id:"tfrecord-to-np"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tfrecord-to-np","aria-hidden":"true"}},[e._v("#")]),e._v(" tfrecord_to_np")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-util-tfrecord-tfrecord-to-np"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-util-tfrecord-tfrecord-to-np","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.util.tfrecord.tfrecord_to_np()")]),e._v(" "),t("p",[e._v("Converts 1 TFRecord (created using fastestimator) to numpy data")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("p",[t("strong",[e._v("file_path")]),e._v(" – Path of TFRecord file")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Dictionary containing numpy data")])])]),e._v(" "),t("h3",{attrs:{id:"get-number-of-examples"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#get-number-of-examples","aria-hidden":"true"}},[e._v("#")]),e._v(" get_number_of_examples")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-util-tfrecord-get-number-of-examples"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-util-tfrecord-get-number-of-examples","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.util.tfrecord.get_number_of_examples()")]),e._v(" "),t("p",[e._v("Returns number of examples in 1 TFRecord")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("file_path")]),e._v(" – Path of TFRecord file")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("show_warning")]),e._v(" – Whether to display warning message")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("compression")]),e._v(" – None, ‘GZIP’ or ‘ZLIB’")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Number of examples in the TFRecord")])])]),e._v(" "),t("h3",{attrs:{id:"get-features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#get-features","aria-hidden":"true"}},[e._v("#")]),e._v(" get_features")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-util-tfrecord-get-features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-util-tfrecord-get-features","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.util.tfrecord.get_features()")]),e._v(" "),t("p",[e._v("Returns the feature information in TFRecords")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("file_path")]),e._v(" – Path of TFRecord file")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("compression")]),e._v(" – None, ‘GZIP’ or ‘ZLIB’")])])])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Returns")])]),e._v(" "),t("p",[e._v("Dictionary containing feature information of TFRecords")])])]),e._v(" "),t("h3",{attrs:{id:"add-summary"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#add-summary","aria-hidden":"true"}},[e._v("#")]),e._v(" add_summary")]),e._v(" "),t("h4",{attrs:{id:"class-fastestimator-util-tfrecord-add-summary"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-fastestimator-util-tfrecord-add-summary","aria-hidden":"true"}},[e._v("#")]),e._v(" class fastestimator.util.tfrecord.add_summary()")]),e._v(" "),t("p",[e._v("Adds summary.json file to existing path with tfrecords.")]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Parameters")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("data_dir")]),e._v(" ("),t("em",[e._v("str")]),e._v(") – Folder path where tfrecords are stored.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("train_prefix")]),e._v(" ("),t("em",[e._v("str")]),e._v(") – The prefix of all training tfrecord files.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature_name")]),e._v(" ("),t("em",[e._v("list")]),e._v(") – Feature name in the tfrecord in a list.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("feature_dtype")]),e._v(" ("),t("em",[e._v("list")]),e._v(") – Original data type for specific feature, this is used for decoding purpose.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("eval_prefix")]),e._v(" ("),t("em",[e._v("str")]),e._v("*, *"),t("em",[e._v("optional")]),e._v(") – The prefix of all evaluation tfrecord files. Defaults to None.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("num_train_examples")]),e._v(" ("),t("em",[e._v("int")]),e._v("*, *"),t("em",[e._v("optional")]),e._v(") – The total number of training examples, if None, it will calculate automatically. Defaults to None.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("num_eval_examples")]),e._v(" ("),t("em",[e._v("int")]),e._v("*, *"),t("em",[e._v("optional")]),e._v(") – The total number of validation examples, if None, it will calculate automatically. Defaults to None.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("compression")]),e._v(" ("),t("em",[e._v("str")]),e._v("*, *"),t("em",[e._v("optional")]),e._v(") – None, ‘GZIP’ or ‘ZLIB’. Defaults to None.")])])])])])])},[],!1,null,null,null);a.default=s.exports}}]);