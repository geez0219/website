(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{188:function(e,t,a){"use strict";a.r(t);var n=a(0),r=Object(n.a)({},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("If you ever go to a zoo, it may not be surprising to see that animals\nall have 3 parts: head, body and leg. Among different animals, no matter\nhow much their appearances may vary, the differences are nothing but\ndifferent arrangements of the 3 common parts.")]),e._v(" "),a("p",[e._v("Similarly, in the deep learning model zoo, every model can be described\nin 3 components: model architecture, data pipeline and training\nstrategy. Each component of the model serves its unique purpose and\nfunctionality:")]),e._v(" "),a("ul",[a("li",[e._v("Model Architecture: stores trainable & differentiable operations.")]),e._v(" "),a("li",[e._v("Data Pipeline: performs series of preprocess operations and\ntransports data from disk/RAM to model.")]),e._v(" "),a("li",[e._v("Training Strategy: iterates data pipeline and model architecture in\nan optimization process.")])]),e._v(" "),a("p",[e._v("Each of the component above represents a critical building block of\nFastEstimator and the story begins with them.")]),e._v(" "),a("h1",{attrs:{id:"overview"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#overview","aria-hidden":"true"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),a("p",[e._v("There are 3 main API components that users will be interacting with:\n"),a("code",[e._v("Pipeline")]),e._v(", "),a("code",[e._v("Network")]),e._v(" and "),a("code",[e._v("Estimator")]),e._v(". The workflow of FastEstimator is\na 3-step process as shown below in the Mnist example.")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.preprocess import Minmax, Onehot, Reshape\nfrom fastestimator.estimator.estimator import Estimator\nfrom fastestimator.pipeline.pipeline import Pipeline\nfrom fastestimator.network.network import Network\nfrom fastestimator.application.lenet import LeNet\nimport tensorflow as tf\n\ndef get_estimator():\n\n    #prepare training and validation data\n    (x_train,y_train),(x_eval,y_eval) = tf.keras.datasets.mnist.load_data()\n\n    # Step 1: Define Pipeline\n    pipeline = Pipeline(batch_size=32,\n                        feature_name=["x","y"],\n                        train_data={"x":x_train,"y":y_train},\n                        validation_data={"x":x_eval, "y":y_eval},\n                        transform_train=[[Reshape([28,28,1]), Minmax()], \n                                         [Onehot(10)]])\n\n    #Step2: Define Network\n    network = Network(model=LeNet(input_name="x",output_name="y"),\n                      loss="categorical_crossentropy",\n                      metrics=["acc"],\n                      optimizer="adam")\n\n    #Step3: Define Estimator\n    estimator = Estimator(network=network,\n                          pipeline=pipeline,\n                          epochs=2)\n    return estimator\n')])])]),a("h1",{attrs:{id:"pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pipeline","aria-hidden":"true"}},[e._v("#")]),e._v(" Pipeline")]),e._v(" "),a("h2",{attrs:{id:"overview-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#overview-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),a("p",[e._v("Data pipeline is responsible for providing data from disk/memory to\nmodel. It includes data preprocessing operations before training loop\nand during training loop. The details of each argument of "),a("code",[e._v("Pipeline")]),e._v(" can\nbe found in\n"),a("a",{attrs:{href:"https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#pipeline",target:"_blank",rel:"noopener noreferrer"}},[e._v("pipeline-api"),a("OutboundLink")],1),e._v(",\nbut let's talk about several important ones here:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("train_data")]),e._v(": The training data in disk (csv) or memory (dict)\nbefore creating tfrecords. Ignore it when using existing tfrecords.")]),e._v(" "),a("li",[a("code",[e._v("validation_data")]),e._v(": The validation data in disk (csv) or memory\n(dict) before creating tfrecords. It can also be split ratio of\n"),a("code",[e._v("train_data")]),e._v(" from [0-1]. Ignore it when using existing tfrecords\nor have no valdiation data.")]),e._v(" "),a("li",[a("code",[e._v("transform_dataset")]),e._v(": Series of operations on individual features\nbefore creating tfrecords.")]),e._v(" "),a("li",[a("code",[e._v("transform_train")]),e._v(": Series of tensor operations on individual\nfeatures during training loop.")])]),e._v(" "),a("h2",{attrs:{id:"preprocess-before-training-loop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#preprocess-before-training-loop","aria-hidden":"true"}},[e._v("#")]),e._v(" Preprocess (before training loop)")]),e._v(" "),a("p",[e._v("There are some preprocessing operations that can be applied before\ntraining loop (e.g. Minmax). In order to ensure a fast training speed,\nit is recommended to apply those operations once and for all before\ntraining happens. FastEstimator offers commonly used preprocessing\nmodules in\n"),a("a",{attrs:{href:"https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#dynamic-preprocess",target:"_blank",rel:"noopener noreferrer"}},[e._v("dynamic-preprocess"),a("OutboundLink")],1),e._v("\n. User can use them in "),a("code",[e._v("transform_dataset")]),e._v(" argument.")]),e._v(" "),a("p",[e._v("For example, given two features x and y, if you want to proprocess them\nin the following way before training:")]),e._v(" "),a("ul",[a("li",[e._v("x: mnist images with size [28,28]--\x3e resize to [50, 50] --\x3e\nnormalize pixel to [0,1]")]),e._v(" "),a("li",[e._v("y: mnist scalar label, do nothing.")])]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax\nfrom fastestimator.pipeline.static.preprocess import Reshape, Onehot\nimport tensorflow as tf\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\npipeline = Pipeline(...\n                    feature_name=["x", "y"],\n                    train_data={"x": x_train, "y": y_train},\n                    transform_dataset=[[Resize([50,50]), Minmax()], \n                                       []],\n                    ...)\n')])])]),a("p",[e._v("If you have a specific preprocessing needs, you can customize a\npreprocessing module. Let's add some noise to the image before the\n"),a("code",[e._v("Minmax")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.dynamic.preprocess import AbstractPreprocessing\nfrom fastestimator.pipeline.dynamic.preprocess import Resize, Minmax\nimport tensorflow as tf\nimport numpy as np\n\nclass AddNoise(AbstractPreprocessing):\n    def transform(self, data, feature=None):\n        data = data + 10 * np.random.rand(data.shape[0], data.shape[1])\n        return data\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\npipeline = Pipeline(...\n                    feature_name=["x", "y"],\n                    train_data={"x": x_train, "y": y_train},\n                    transform_dataset=[[Resize([50,50]), AddNoise(), Minmax()], \n                                       []],\n                    ...)\n')])])]),a("h2",{attrs:{id:"preprocess-during-training-loop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#preprocess-during-training-loop","aria-hidden":"true"}},[e._v("#")]),e._v(" Preprocess (during training loop)")]),e._v(" "),a("p",[e._v('In the previous example, we added some random noise to the image before\ntraining loop. As you may notice, the drawback is that the random noise\nnot being "random" enough, as we are dealing with image with same\nnoise every iteration. One natural answer is to add the noise at run\ntime.')]),e._v(" "),a("p",[e._v("Moreover, there are some operations that are better off applied at\nruntime such as [onehot encoder]{.title-ref}. Because we don't want our\ntfrecords to include bunch of useless zeros. Therefore, we need one more\ntype of preprocess that can execute on the fly.")]),e._v(" "),a("p",[e._v("In FastEstimator, on-the-fly preprocessing is implemented in tensorflow,\nthese preprocessing modules are passed through "),a("code",[e._v("transform_train")]),e._v("\nargument. Users can use existing module in\n"),a("a",{attrs:{href:"https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#static-preprocess",target:"_blank",rel:"noopener noreferrer"}},[e._v("static-preprocess"),a("OutboundLink")],1),e._v("\nor customize one for specific needs.")]),e._v(" "),a("p",[e._v("For example, if we want the following process to happen during trainign\nloop:")]),e._v(" "),a("ul",[a("li",[e._v("x: reshape the image data from [2500] to [50, 50, 1]")]),e._v(" "),a("li",[e._v("y: apply one-hot encoder to scalar label")])]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax\nfrom fastestimator.pipeline.static.preprocess import Reshape, Onehot\nimport tensorflow as tf\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\npipeline = Pipeline(...\n                    feature_name=["x", "y"],\n                    train_data={"x": x_train, "y": y_train},\n                    transform_dataset=[[Resize([50,50]), Minmax()], \n                                       []],\n                    transform_train= [[Reshape([50,50,1])], \n                                      [Onehot(10)]])\n')])])]),a("p",[e._v("Next, we add noise on the fly:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.preprocess import AbstractPreprocessing\nfrom fastestimator.pipeline.dynamic.preprocess import Resize, Minmax\nfrom fastestimator.pipeline.static.preprocess import Reshape, Onehot\nimport tensorflow as tf\nimport numpy as np\n\nclass AddNoise(AbstractPreprocessing):\n    def transform(self, data, decoded_data=None):\n        data = data + tf.random.uniform(data.shape)\n        return data\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\npipeline = Pipeline(...\n                    feature_name=["x", "y"],\n                    train_data={"x": x_train, "y": y_train},\n                    transform_dataset=[[Resize([50,50]), Minmax()], \n                                       []],\n                    transform_train= [[Reshape([50,50,1]), AddNoise()], \n                                      [Onehot(10)]])\n')])])]),a("h2",{attrs:{id:"augmentation-during-training-loop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#augmentation-during-training-loop","aria-hidden":"true"}},[e._v("#")]),e._v(" Augmentation (during training loop)")]),e._v(" "),a("p",[e._v("In FastEstimator, augmentation module is same as on-the-fly\npreprocessing except for one difference: augmentation allows two or more\nfeatures to share the same information. For example, in a segmentation\ntask, image and mask have to be tranformed in the same manner, meaning\nthat they share the same transformation matrix.")]),e._v(" "),a("p",[e._v("Similar to on-the-fly preprocessing, augmentation is passed through\n"),a("code",[e._v("transform_train")]),e._v(" argument. FastEstimator provides default\n"),a("a",{attrs:{href:"https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#augmentation",target:"_blank",rel:"noopener noreferrer"}},[e._v("2D-augmentation"),a("OutboundLink")],1),e._v(",\nfor example, if we want to apply the following operation to mnist image:")]),e._v(" "),a("ul",[a("li",[e._v("random rotation between -25 degrees to 25 degrees")]),e._v(" "),a("li",[e._v("random zoom between 0.8 and 1.0,")])]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.preprocess import Reshape, Onehot\nfrom fastestimator.pipeline.static.augmentation import Augmentation\nfrom fastestimator.pipeline.dynamic.preprocess import Minmax\nimport tensorflow as tf\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\naug_obj = Augmentation(rotation_range=25.0, zoom_range=[0.8, 1.0])\npipeline = Pipeline(...\n                    feature_name=["x", "y"],\n                    train_data={"x": x_train, "y": y_train},\n                    transform_dataset=[[Minmax()], \n                                       []],\n                    transform_train= [[Reshape([28,28,1], aug_obj)], \n                                      [Onehot(10)]])\n')])])]),a("p",[e._v("If you want the same augmentation to be applied to other features(when\nthere is mask), just pass the same object:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('aug_obj = Augmentation(rotation_range=25.0, zoom_range=[0.8, 1.0])\npipeline = Pipeline(....\n                    feature_name=["image", "mask"],\n                    transform_train = [[Reshape([100,100,1]), Minmax(), aug_obj], \n                                      [Reshape([100,100,1]), aug_obj]])\n')])])]),a("p",[e._v("User can also customize augmentation to achieve specific goal, for\nexample, we want to add the same random noise for image and mask during\ntraining:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.augmentation import AbstractAugmentation\nfrom fastestimator.general.pipeline import Pipeline\nimport tensorflow as tf\n\n# Define customized augmentation\nclass AddNoise(AbstractAugmentation):\n    def __init__(self, mode="train"):\n        self.mode = mode\n        self.decoded_data = None\n        self.feature_name = None\n\n    def setup(self):\n        #we define information shared between features in setup\n        self.random_noise = tf.random_uniform([100,100,1], minval=0, maxval=1)\n\n    def transform(self, data):\n        data = data + self.random_noise\n        return data\n\naug_obj = AddNoise()\npipeline = Pipeline(....\n                    feature_name=["image", "mask"],\n                    transform_train = [[Reshape([100,100,1]), Minmax(), aug_obj], \n                                      [Reshape([100,100,1]), aug_obj]])\n')])])]),a("h2",{attrs:{id:"data-filter"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#data-filter","aria-hidden":"true"}},[e._v("#")]),e._v(" Data Filter")]),e._v(" "),a("p",[e._v("We can also filter out some example for imbalanced training,\nFastEstimator provides built-in filter based on scalar feature. For\nexample, if we want to filter out example with label=1,3,5,7,9:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.filter import Filter\nfrom fastestimator.pipeline.pipeline import Pipeline\n\nmy_filter = Filter(feature_name=["y", "y", "y", "y", "y"],\n                   filter_value=[1, 3, 5, 7, 9],\n                   keep_prob= [0.0, 0.0, 0.0, 0.0, 0.0])\npipeline = Pipeline(....\n                    data_filter=my_filter)\n')])])]),a("p",[e._v("User can customize their own filter for more complex filters, for\nexample, if we only want to use the example if sum of the image is\ngreater than 10:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.filter import Filter\nfrom fastestimator.pipeline.pipeline import Pipeline\n\nclass my_filter(Filter):\n    def __init__(self, mode="train"):\n        self.mode = mode\n\n    def predicate_fn(self, dataset):\n        #we only use the example when predicate is True\n        predicate = tf.greater(tf.reduce_sum(dataset["x"]), 10)\n        return predicate\n\npipeline = Pipeline(....\n                    data_filter=my_filter)\n')])])]),a("h2",{attrs:{id:"pipeline-debugging"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pipeline-debugging","aria-hidden":"true"}},[e._v("#")]),e._v(" Pipeline Debugging")]),e._v(" "),a("p",[e._v("Once you created your pipeline instace, you can use the\n[show_batches]{.title-ref} method to run the pipeline get the outcome\nin numpy.")]),e._v(" "),a("p",[e._v("For example, if we want to produce tfrecords first and show two batches\nof pipeline outcome:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.preprocess import Minmax, Onehot, Reshape\nfrom fastestimator.pipeline.pipeline import Pipeline\nimport tensorflow as tf\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\npipeline = Pipeline(batch_size=32,\n                    feature_name=["x", "y"],\n                    train_data={"x": x_train, "y": y_train},\n                    transform_train= [[Reshape([28,28,1]), Minmax()], \n                                      [Onehot(10)]])\ndata= pipeline.show_batches(num_batches=2)\nprint(data)\n')])])]),a("p",[e._v("If we want to use existing tfrecords and show the outcome of pipleine,\nwe can get rid of "),a("code",[e._v("train_data")]),e._v(" and provide the tfrecords path in\n"),a("code",[e._v("show_batches")]),e._v(".")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.static.preprocess import Minmax, Onehot, Reshape\nfrom fastestimator.pipeline.pipeline import Pipeline\n\npipeline = Pipeline(batch_size=32,\n                    feature_name=["x", "y"],\n                    transform_train= [[Reshape([28,28,1]), Minmax()], \n                                      [Onehot(10)]])\ndata= pipeline.show_batches(inputs="/your/tfrecord/path", num_batches=2)\nprint(data)\n')])])]),a("h1",{attrs:{id:"network"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#network","aria-hidden":"true"}},[e._v("#")]),e._v(" Network")]),e._v(" "),a("h2",{attrs:{id:"overview-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#overview-3","aria-hidden":"true"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),a("p",[e._v("In FastEstimator, [Network]{.title-ref} contains the model architecture\nand optimization related information. User can refer to\n"),a("a",{attrs:{href:"https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#network",target:"_blank",rel:"noopener noreferrer"}},[e._v("network-api"),a("OutboundLink")],1),e._v("\nto find detail arguments. [Network]{.title-ref} arguments have full\ncompatibility with "),a("code",[e._v("tf.keras")]),e._v(", here's one example of network :")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.network.network import Network\nfrom fastestimator.application.lenet import LeNet\n\nnetwork = Network(model=LeNet(input_name="x",output_name="y"),\n                  loss="categorical_crossentropy",\n                  metrics=["acc"],\n                  optimizer="adam")\n')])])]),a("h2",{attrs:{id:"model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#model","aria-hidden":"true"}},[e._v("#")]),e._v(" Model")]),e._v(" "),a("p",[e._v("model argument takes an uncompiled "),a("code",[e._v("tf.keras.Model")]),e._v(" instance. In order\nfor pipeline to feed data to the correct layer, users have to make sure\nthe Input/Output layer's name matches with pipeline's feature name.")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.pipeline import Pipeline\nfrom fastestimator.network.network import Network\nimport tensorflow as tf\n\ndef my_network():\n    input_layer = tf.keras.layers.Input(..., name="x")\n    .....\n    output_layer = tf.keras.layers.Dense(...., name = "y")\n    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n    return model\n\npipeline = Pipeline(feature_name=["x", "y"],\n                    ...)\n\nnetwork = Network(model=my_network(),\n                  ...)\n')])])]),a("h2",{attrs:{id:"loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss","aria-hidden":"true"}},[e._v("#")]),e._v(" Loss")]),e._v(" "),a("p",[e._v("All standard "),a("code",[e._v("tf.keras")]),e._v(" loss functions are supported, in this case, you\ncan simply provide the name of the loss as a string. Please refer\nofficial\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/losses",target:"_blank",rel:"noopener noreferrer"}},[e._v("Losses"),a("OutboundLink")],1),e._v(" for\na complete list of "),a("code",[e._v("tf.keras")]),e._v(" loss functions.")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('network = Network(...,\n                  loss="categorical_crossentropy",\n                  ...)\n')])])]),a("p",[e._v("User can also define customized loss by tensorflow.keras:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("import tensorflow.keras.backend as K\n\ndef rmse_loss(y_true, y_pred):\n    rmse = K.sqrt(K.mean(K.square(y_true - y_pred)))\n    return rmse\n\nnetwork = Network(...,\n                  loss=rmse_loss,\n                  ...)\n")])])]),a("h2",{attrs:{id:"metrics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#metrics","aria-hidden":"true"}},[e._v("#")]),e._v(" Metrics")]),e._v(" "),a("p",[e._v("Metrics also work similarly to loss. For standard Keras metrics (e.g.,\naccuracy), you can simply specify the name of metric(s) in a list.\nPlease refer official\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/metrics",target:"_blank",rel:"noopener noreferrer"}},[e._v("Metrics"),a("OutboundLink")],1),e._v("\nfor a complete list of metric functions.")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('network = Network(...,\n                  metrics=["acc"],\n                  ...)\n')])])]),a("p",[e._v("User can also define customized metrics by tensorflow.keras:")]),e._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("import")]),e._v(" tensorflow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("backend "),a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("as")]),e._v(" K\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("def")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("dice")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("y_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" y_pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n    intersection "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" K"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("y_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" y_pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n    coef "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" intersection "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("+")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("/")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("K"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("y_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("+")]),e._v(" K"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("y_pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("+")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("return")]),e._v(" coef\n\nnetwork "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" Network"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("\n                metrics"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("dice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n")])])]),a("h2",{attrs:{id:"optimizer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#optimizer","aria-hidden":"true"}},[e._v("#")]),e._v(" Optimizer")]),e._v(" "),a("p",[e._v("FastEstimator is compatible with optimizers from "),a("code",[e._v("tf.keras.optimizer")]),e._v(",\nplease refer to\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers",target:"_blank",rel:"noopener noreferrer"}},[e._v("Optimizers"),a("OutboundLink")],1),e._v("\nfor a compelete list of optimizers. One can simply use string with\ndefault optimizer settings:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('network = Network(...,\n                  optimizer="adam",\n                  ...)\n')])])]),a("p",[e._v("Users can also pass an optimizer instance with custom settings:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("network = Network(...,\n                  optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.95),\n                  ...)\n")])])]),a("h2",{attrs:{id:"model-save-path"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#model-save-path","aria-hidden":"true"}},[e._v("#")]),e._v(" Model Save Path")]),e._v(" "),a("p",[e._v("In FastEstimator, model artifacts will be saved in a random path in\n[/tmp]{.title-ref} by default. If user wants to save model to a specific\ndirectory, simply pass the directory to the "),a("code",[e._v("model_dir")]),e._v(": Once network\ninstance is created, user can access the saving path by\n"),a("code",[e._v("network.model_dir")]),e._v(".")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('network = Network(...,\n                  model_dir="/home/model",\n                  ...)\n')])])]),a("h1",{attrs:{id:"estimator"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#estimator","aria-hidden":"true"}},[e._v("#")]),e._v(" Estimator")]),e._v(" "),a("p",[e._v("In FastEstimator, the [Estimator]{.title-ref} stores information about\nthe optimization process. It takes both [pipeline]{.title-ref} and\n[network]{.title-ref} as input, configures them properly for different\ntraining settings. Next, we show several places where user can customize\nthe training loop.")]),e._v(" "),a("h2",{attrs:{id:"callbacks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#callbacks","aria-hidden":"true"}},[e._v("#")]),e._v(" Callbacks")]),e._v(" "),a("p",[e._v("Users can use all callbacks in "),a("code",[e._v("tf.keras.callbacks")]),e._v(" except for three:")]),e._v(" "),a("ul",[a("li",[e._v("`LearningRateScheduler`: Use\n"),a("code",[e._v("fastestimator.estimator.callbacks.LearningRateScheduler")])]),e._v(" "),a("li",[e._v("`ReduceLROnPlateau`: Use\n"),a("code",[e._v("fastestimator.estimator.callbacks.ReduceLROnPlateau")])]),e._v(" "),a("li",[e._v("`EarlyStopping`: Use\n"),a("code",[e._v("fastestimator.estimator.callbacks.EarlyStopping")])])]),e._v(" "),a("p",[e._v("For other callbacks, please refer to\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks",target:"_blank",rel:"noopener noreferrer"}},[e._v("Callbacks"),a("OutboundLink")],1),e._v("\nin Tensorflow Keras. Next, we present an example of using callbacks in\nFastEstimator:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("from fastestimator.estimator.callbacks import LearningRateScheduler, EarlyStopping\nfrom fastestimator.network.lrscheduler import CyclicScheduler\nfrom fastestimator.estimator.estimator import Estimator\nfrom tensorflow.keras.callbacks import TensorBoard\n\ncallbacks = [LearningRateScheduler(schedule=CyclicScheduler()),\n             EarlyStopping(patience=3),\n             TensorBoard()]\n\nestimator = Estimator(...,\n                      callbacks=callbacks,\n                      ...)\n")])])]),a("h2",{attrs:{id:"custom-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#custom-steps","aria-hidden":"true"}},[e._v("#")]),e._v(" Custom Steps")]),e._v(" "),a("p",[e._v("By default, the number of training steps and validation steps for each\nepoch is calculated as:")]),e._v(" "),a("ul",[a("li",[e._v("steps_per_epoch = num_examples / batch_size / num_process")]),e._v(" "),a("li",[e._v("validation_steps = num_examples / batch_size")])]),e._v(" "),a("p",[e._v("where [num_process]{.title-ref} is the number of parallel training\nprocesses, in multi-GPU training, it is the number of GPUs. User can\noverride the number of training and validation steps in the Estimator:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("estimator = Estimator(...,\n                      steps_per_epoch=100,\n                      validation_steps=100,\n                      ...)\n")])])]),a("h2",{attrs:{id:"logging-configuration"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#logging-configuration","aria-hidden":"true"}},[e._v("#")]),e._v(" Logging Configuration")]),e._v(" "),a("p",[e._v("During trainig, the training logs will appear every 100 steps as\ndefault, users can change the logging interval through "),a("code",[e._v("log_steps")]),e._v("\nargument, for example, if we want the log to appear every 10 steps:")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("estimator = Estimator(...,\n                      log_steps=10,\n                      ...)\n")])])]),a("p",[e._v("The training speed may decrease if the logging interval is too small.")]),e._v(" "),a("h1",{attrs:{id:"other-utility-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#other-utility-functions","aria-hidden":"true"}},[e._v("#")]),e._v(" Other Utility Functions")]),e._v(" "),a("p",[e._v("Outside of core API, FastEstimator offers some useful utilify functions\nthat can be used independently.")]),e._v(" "),a("h2",{attrs:{id:"tfrecorder"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tfrecorder","aria-hidden":"true"}},[e._v("#")]),e._v(" TFRecorder")]),e._v(" "),a("p",[a("code",[e._v("fastestimator.util.tfrecord.TFRecorder")]),e._v(" can help you easily create\ntfrecord from any data. The usage of TFRecorder is very similar to\n"),a("code",[e._v("Pipeline")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax\nfrom fastestimator.util.tfrecord import TFRecorder\nimport tensorflow as tf\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\ntfrecorder = TFRecorder(feature_name=["x", "y"],\n                        train_data={"x": x_train, "y": y_train},\n                        validation_data = 0.2,\n                        transform_dataset=[[Resize([50,50]), Minmax()], \n                                            []])\ntfrecorder.create_tfrecord(save_dir="/home/data")\n')])])]),a("h2",{attrs:{id:"add-summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-summary","aria-hidden":"true"}},[e._v("#")]),e._v(" add_summary")]),e._v(" "),a("p",[e._v("While creating tfrecords, both TFRecorder or FastEstimator produce a\nsummary file that is required for training. If you have previously built\ntfrecords outside of FastEstimator or TFRecorder, you can use\n"),a("code",[e._v("add_summary")]),e._v(" to create the summary file for training.")]),e._v(" "),a("div",{staticClass:"language-{.sourceCode .python} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('from fastestimator.util.tfrecord import add_summary, get_features\n\n# First, get feature name and related information\nprint(get_features("/data/data/Xray/chestfrontal/chestfrontal_train_0000.tfrecords"))\n\n# Next, fill in the required field\nadd_summary(data_dir="/data/data/Xray/chestfrontal", \n            train_prefix="chestfrontal_train", \n            eval_prefix= "chestfrontal_val", \n            feature_name=["image_raw", "image_labels"], \n            feature_dtype=["uint8", "int64"])\n')])])]),a("h1",{attrs:{id:"full-code-demo"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#full-code-demo","aria-hidden":"true"}},[e._v("#")]),e._v(" Full Code Demo")]),e._v(" "),a("ul",[a("li",[e._v("Image Classification:\n"),a("a",{attrs:{href:"https://github.build.ge.com/edisonaitk/public_model/blob/master/classification_mnist/mnist.ipynb",target:"_blank",rel:"noopener noreferrer"}},[e._v("Mnist-Classification"),a("OutboundLink")],1)]),e._v(" "),a("li",[e._v("Image Segmentation:\n"),a("a",{attrs:{href:"https://github.build.ge.com/edisonaitk/public_model/blob/master/segmentation_cub200/cub200.ipynb",target:"_blank",rel:"noopener noreferrer"}},[e._v("Cub200-Segmentation"),a("OutboundLink")],1)]),e._v(" "),a("li",[e._v("Natural Language Processing:\n"),a("a",{attrs:{href:"https://github.build.ge.com/edisonaitk/public_model/blob/master/sentiment_classification_imdb/imdb.ipynb",target:"_blank",rel:"noopener noreferrer"}},[e._v("IMDB-Review"),a("OutboundLink")],1)])])])},[],!1,null,null,null);t.default=r.exports}}]);