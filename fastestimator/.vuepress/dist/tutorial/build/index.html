<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Buiding model with FastEstimator | FastEstimator</title>
    <meta name="description" content="Just Playing Around">
    
    
    <link rel="preload" href="/assets/css/0.styles.b73f4d1c.css" as="style"><link rel="preload" href="/assets/js/app.5136acb6.js" as="script"><link rel="preload" href="/assets/js/2.6ec3d9bf.js" as="script"><link rel="preload" href="/assets/js/7.85ca8dce.js" as="script"><link rel="prefetch" href="/assets/js/10.4885436f.js"><link rel="prefetch" href="/assets/js/11.b7ea0b1a.js"><link rel="prefetch" href="/assets/js/3.7699c289.js"><link rel="prefetch" href="/assets/js/4.3d306c4a.js"><link rel="prefetch" href="/assets/js/5.988d5ac7.js"><link rel="prefetch" href="/assets/js/6.ab0016fe.js"><link rel="prefetch" href="/assets/js/8.4f379545.js"><link rel="prefetch" href="/assets/js/9.0849c600.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b73f4d1c.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">FastEstimator</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/tutorial/build/..html" class="nav-link">Home</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title">Tutorial</span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tutorial/build/tutorial/install/" class="nav-link">install</a></li><li class="dropdown-item"><!----> <a href="/tutorial/build/tutorial/build/" class="nav-link">build model</a></li><li class="dropdown-item"><!----> <a href="/tutorial/build/tutorial/train/" class="nav-link">train model</a></li></ul></div></div><div class="nav-item"><a href="/tutorial/build/api/" class="nav-link">API</a></div><div class="nav-item"><a href="https://github.com/fastestimator/fastestimator" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/tutorial/build/..html" class="nav-link">Home</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title">Tutorial</span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tutorial/build/tutorial/install/" class="nav-link">install</a></li><li class="dropdown-item"><!----> <a href="/tutorial/build/tutorial/build/" class="nav-link">build model</a></li><li class="dropdown-item"><!----> <a href="/tutorial/build/tutorial/train/" class="nav-link">train model</a></li></ul></div></div><div class="nav-item"><a href="/tutorial/build/api/" class="nav-link">API</a></div><div class="nav-item"><a href="https://github.com/fastestimator/fastestimator" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Buiding model with FastEstimator</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/tutorial/build/#overview-2" class="sidebar-link">Overview</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#preprocess-before-training-loop" class="sidebar-link">Preprocess (before training loop)</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#preprocess-during-training-loop" class="sidebar-link">Preprocess (during training loop)</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#augmentation-during-training-loop" class="sidebar-link">Augmentation (during training loop)</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#data-filter" class="sidebar-link">Data Filter</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#pipeline-debugging" class="sidebar-link">Pipeline Debugging</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#overview-3" class="sidebar-link">Overview</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#model" class="sidebar-link">Model</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#loss" class="sidebar-link">Loss</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#metrics" class="sidebar-link">Metrics</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#optimizer" class="sidebar-link">Optimizer</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#model-save-path" class="sidebar-link">Model Save Path</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#callbacks" class="sidebar-link">Callbacks</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#custom-steps" class="sidebar-link">Custom Steps</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#logging-configuration" class="sidebar-link">Logging Configuration</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#tfrecorder" class="sidebar-link">TFRecorder</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/tutorial/build/#add-summary" class="sidebar-link">add_summary</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p>If you ever go to a zoo, it may not be surprising to see that animals
all have 3 parts: head, body and leg. Among different animals, no matter
how much their appearances may vary, the differences are nothing but
different arrangements of the 3 common parts.</p> <p>Similarly, in the deep learning model zoo, every model can be described
in 3 components: model architecture, data pipeline and training
strategy. Each component of the model serves its unique purpose and
functionality:</p> <ul><li>Model Architecture: stores trainable &amp; differentiable operations.</li> <li>Data Pipeline: performs series of preprocess operations and
transports data from disk/RAM to model.</li> <li>Training Strategy: iterates data pipeline and model architecture in
an optimization process.</li></ul> <p>Each of the component above represents a critical building block of
FastEstimator and the story begins with them.</p> <h1 id="overview"><a href="#overview" aria-hidden="true" class="header-anchor">#</a> Overview</h1> <p>There are 3 main API components that users will be interacting with:
<code>Pipeline</code>, <code>Network</code> and <code>Estimator</code>. The workflow of FastEstimator is
a 3-step process as shown below in the Mnist example.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.preprocess import Minmax, Onehot, Reshape
from fastestimator.estimator.estimator import Estimator
from fastestimator.pipeline.pipeline import Pipeline
from fastestimator.network.network import Network
from fastestimator.application.lenet import LeNet
import tensorflow as tf

def get_estimator():

    #prepare training and validation data
    (x_train,y_train),(x_eval,y_eval) = tf.keras.datasets.mnist.load_data()

    # Step 1: Define Pipeline
    pipeline = Pipeline(batch_size=32,
                        feature_name=[&quot;x&quot;,&quot;y&quot;],
                        train_data={&quot;x&quot;:x_train,&quot;y&quot;:y_train},
                        validation_data={&quot;x&quot;:x_eval, &quot;y&quot;:y_eval},
                        transform_train=[[Reshape([28,28,1]), Minmax()], 
                                         [Onehot(10)]])

    #Step2: Define Network
    network = Network(model=LeNet(input_name=&quot;x&quot;,output_name=&quot;y&quot;),
                      loss=&quot;categorical_crossentropy&quot;,
                      metrics=[&quot;acc&quot;],
                      optimizer=&quot;adam&quot;)

    #Step3: Define Estimator
    estimator = Estimator(network=network,
                          pipeline=pipeline,
                          epochs=2)
    return estimator
</code></pre></div><h1 id="pipeline"><a href="#pipeline" aria-hidden="true" class="header-anchor">#</a> Pipeline</h1> <h2 id="overview-2"><a href="#overview-2" aria-hidden="true" class="header-anchor">#</a> Overview</h2> <p>Data pipeline is responsible for providing data from disk/memory to
model. It includes data preprocessing operations before training loop
and during training loop. The details of each argument of <code>Pipeline</code> can
be found in
<a href="https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#pipeline" target="_blank" rel="noopener noreferrer">pipeline-api<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>,
but let's talk about several important ones here:</p> <ul><li><code>train_data</code>: The training data in disk (csv) or memory (dict)
before creating tfrecords. Ignore it when using existing tfrecords.</li> <li><code>validation_data</code>: The validation data in disk (csv) or memory
(dict) before creating tfrecords. It can also be split ratio of
<code>train_data</code> from [0-1]. Ignore it when using existing tfrecords
or have no valdiation data.</li> <li><code>transform_dataset</code>: Series of operations on individual features
before creating tfrecords.</li> <li><code>transform_train</code>: Series of tensor operations on individual
features during training loop.</li></ul> <h2 id="preprocess-before-training-loop"><a href="#preprocess-before-training-loop" aria-hidden="true" class="header-anchor">#</a> Preprocess (before training loop)</h2> <p>There are some preprocessing operations that can be applied before
training loop (e.g. Minmax). In order to ensure a fast training speed,
it is recommended to apply those operations once and for all before
training happens. FastEstimator offers commonly used preprocessing
modules in
<a href="https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#dynamic-preprocess" target="_blank" rel="noopener noreferrer">dynamic-preprocess<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
. User can use them in <code>transform_dataset</code> argument.</p> <p>For example, given two features x and y, if you want to proprocess them
in the following way before training:</p> <ul><li>x: mnist images with size [28,28]--&gt; resize to [50, 50] --&gt;
normalize pixel to [0,1]</li> <li>y: mnist scalar label, do nothing.</li></ul> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax
from fastestimator.pipeline.static.preprocess import Reshape, Onehot
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

pipeline = Pipeline(...
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                    transform_dataset=[[Resize([50,50]), Minmax()], 
                                       []],
                    ...)
</code></pre></div><p>If you have a specific preprocessing needs, you can customize a
preprocessing module. Let's add some noise to the image before the
<code>Minmax</code>:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.dynamic.preprocess import AbstractPreprocessing
from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax
import tensorflow as tf
import numpy as np

class AddNoise(AbstractPreprocessing):
    def transform(self, data, feature=None):
        data = data + 10 * np.random.rand(data.shape[0], data.shape[1])
        return data

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

pipeline = Pipeline(...
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                    transform_dataset=[[Resize([50,50]), AddNoise(), Minmax()], 
                                       []],
                    ...)
</code></pre></div><h2 id="preprocess-during-training-loop"><a href="#preprocess-during-training-loop" aria-hidden="true" class="header-anchor">#</a> Preprocess (during training loop)</h2> <p>In the previous example, we added some random noise to the image before
training loop. As you may notice, the drawback is that the random noise
not being &quot;random&quot; enough, as we are dealing with image with same
noise every iteration. One natural answer is to add the noise at run
time.</p> <p>Moreover, there are some operations that are better off applied at
runtime such as [onehot encoder]{.title-ref}. Because we don't want our
tfrecords to include bunch of useless zeros. Therefore, we need one more
type of preprocess that can execute on the fly.</p> <p>In FastEstimator, on-the-fly preprocessing is implemented in tensorflow,
these preprocessing modules are passed through <code>transform_train</code>
argument. Users can use existing module in
<a href="https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#static-preprocess" target="_blank" rel="noopener noreferrer">static-preprocess<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
or customize one for specific needs.</p> <p>For example, if we want the following process to happen during trainign
loop:</p> <ul><li>x: reshape the image data from [2500] to [50, 50, 1]</li> <li>y: apply one-hot encoder to scalar label</li></ul> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax
from fastestimator.pipeline.static.preprocess import Reshape, Onehot
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

pipeline = Pipeline(...
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                    transform_dataset=[[Resize([50,50]), Minmax()], 
                                       []],
                    transform_train= [[Reshape([50,50,1])], 
                                      [Onehot(10)]])
</code></pre></div><p>Next, we add noise on the fly:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.preprocess import AbstractPreprocessing
from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax
from fastestimator.pipeline.static.preprocess import Reshape, Onehot
import tensorflow as tf
import numpy as np

class AddNoise(AbstractPreprocessing):
    def transform(self, data, decoded_data=None):
        data = data + tf.random.uniform(data.shape)
        return data

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

pipeline = Pipeline(...
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                    transform_dataset=[[Resize([50,50]), Minmax()], 
                                       []],
                    transform_train= [[Reshape([50,50,1]), AddNoise()], 
                                      [Onehot(10)]])
</code></pre></div><h2 id="augmentation-during-training-loop"><a href="#augmentation-during-training-loop" aria-hidden="true" class="header-anchor">#</a> Augmentation (during training loop)</h2> <p>In FastEstimator, augmentation module is same as on-the-fly
preprocessing except for one difference: augmentation allows two or more
features to share the same information. For example, in a segmentation
task, image and mask have to be tranformed in the same manner, meaning
that they share the same transformation matrix.</p> <p>Similar to on-the-fly preprocessing, augmentation is passed through
<code>transform_train</code> argument. FastEstimator provides default
<a href="https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#augmentation" target="_blank" rel="noopener noreferrer">2D-augmentation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>,
for example, if we want to apply the following operation to mnist image:</p> <ul><li>random rotation between -25 degrees to 25 degrees</li> <li>random zoom between 0.8 and 1.0,</li></ul> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.preprocess import Reshape, Onehot
from fastestimator.pipeline.static.augmentation import Augmentation
from fastestimator.pipeline.dynamic.preprocess import Minmax
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
aug_obj = Augmentation(rotation_range=25.0, zoom_range=[0.8, 1.0])
pipeline = Pipeline(...
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                    transform_dataset=[[Minmax()], 
                                       []],
                    transform_train= [[Reshape([28,28,1], aug_obj)], 
                                      [Onehot(10)]])
</code></pre></div><p>If you want the same augmentation to be applied to other features(when
there is mask), just pass the same object:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>aug_obj = Augmentation(rotation_range=25.0, zoom_range=[0.8, 1.0])
pipeline = Pipeline(....
                    feature_name=[&quot;image&quot;, &quot;mask&quot;],
                    transform_train = [[Reshape([100,100,1]), Minmax(), aug_obj], 
                                      [Reshape([100,100,1]), aug_obj]])
</code></pre></div><p>User can also customize augmentation to achieve specific goal, for
example, we want to add the same random noise for image and mask during
training:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.augmentation import AbstractAugmentation
from fastestimator.general.pipeline import Pipeline
import tensorflow as tf

# Define customized augmentation
class AddNoise(AbstractAugmentation):
    def __init__(self, mode=&quot;train&quot;):
        self.mode = mode
        self.decoded_data = None
        self.feature_name = None

    def setup(self):
        #we define information shared between features in setup
        self.random_noise = tf.random_uniform([100,100,1], minval=0, maxval=1)

    def transform(self, data):
        data = data + self.random_noise
        return data

aug_obj = AddNoise()
pipeline = Pipeline(....
                    feature_name=[&quot;image&quot;, &quot;mask&quot;],
                    transform_train = [[Reshape([100,100,1]), Minmax(), aug_obj], 
                                      [Reshape([100,100,1]), aug_obj]])
</code></pre></div><h2 id="data-filter"><a href="#data-filter" aria-hidden="true" class="header-anchor">#</a> Data Filter</h2> <p>We can also filter out some example for imbalanced training,
FastEstimator provides built-in filter based on scalar feature. For
example, if we want to filter out example with label=1,3,5,7,9:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.filter import Filter
from fastestimator.pipeline.pipeline import Pipeline

my_filter = Filter(feature_name=[&quot;y&quot;, &quot;y&quot;, &quot;y&quot;, &quot;y&quot;, &quot;y&quot;],
                   filter_value=[1, 3, 5, 7, 9],
                   keep_prob= [0.0, 0.0, 0.0, 0.0, 0.0])
pipeline = Pipeline(....
                    data_filter=my_filter)
</code></pre></div><p>User can customize their own filter for more complex filters, for
example, if we only want to use the example if sum of the image is
greater than 10:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.filter import Filter
from fastestimator.pipeline.pipeline import Pipeline

class my_filter(Filter):
    def __init__(self, mode=&quot;train&quot;):
        self.mode = mode

    def predicate_fn(self, dataset):
        #we only use the example when predicate is True
        predicate = tf.greater(tf.reduce_sum(dataset[&quot;x&quot;]), 10)
        return predicate

pipeline = Pipeline(....
                    data_filter=my_filter)
</code></pre></div><h2 id="pipeline-debugging"><a href="#pipeline-debugging" aria-hidden="true" class="header-anchor">#</a> Pipeline Debugging</h2> <p>Once you created your pipeline instace, you can use the
[show_batches]{.title-ref} method to run the pipeline get the outcome
in numpy.</p> <p>For example, if we want to produce tfrecords first and show two batches
of pipeline outcome:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.preprocess import Minmax, Onehot, Reshape
from fastestimator.pipeline.pipeline import Pipeline
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

pipeline = Pipeline(batch_size=32,
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                    transform_train= [[Reshape([28,28,1]), Minmax()], 
                                      [Onehot(10)]])
data= pipeline.show_batches(num_batches=2)
print(data)
</code></pre></div><p>If we want to use existing tfrecords and show the outcome of pipleine,
we can get rid of <code>train_data</code> and provide the tfrecords path in
<code>show_batches</code>.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.static.preprocess import Minmax, Onehot, Reshape
from fastestimator.pipeline.pipeline import Pipeline

pipeline = Pipeline(batch_size=32,
                    feature_name=[&quot;x&quot;, &quot;y&quot;],
                    transform_train= [[Reshape([28,28,1]), Minmax()], 
                                      [Onehot(10)]])
data= pipeline.show_batches(inputs=&quot;/your/tfrecord/path&quot;, num_batches=2)
print(data)
</code></pre></div><h1 id="network"><a href="#network" aria-hidden="true" class="header-anchor">#</a> Network</h1> <h2 id="overview-3"><a href="#overview-3" aria-hidden="true" class="header-anchor">#</a> Overview</h2> <p>In FastEstimator, [Network]{.title-ref} contains the model architecture
and optimization related information. User can refer to
<a href="https://github.build.ge.com/pages/edisonaitk/fastestimator/api.html#network" target="_blank" rel="noopener noreferrer">network-api<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
to find detail arguments. [Network]{.title-ref} arguments have full
compatibility with <code>tf.keras</code>, here's one example of network :</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.network.network import Network
from fastestimator.application.lenet import LeNet

network = Network(model=LeNet(input_name=&quot;x&quot;,output_name=&quot;y&quot;),
                  loss=&quot;categorical_crossentropy&quot;,
                  metrics=[&quot;acc&quot;],
                  optimizer=&quot;adam&quot;)
</code></pre></div><h2 id="model"><a href="#model" aria-hidden="true" class="header-anchor">#</a> Model</h2> <p>model argument takes an uncompiled <code>tf.keras.Model</code> instance. In order
for pipeline to feed data to the correct layer, users have to make sure
the Input/Output layer's name matches with pipeline's feature name.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.pipeline import Pipeline
from fastestimator.network.network import Network
import tensorflow as tf

def my_network():
    input_layer = tf.keras.layers.Input(..., name=&quot;x&quot;)
    .....
    output_layer = tf.keras.layers.Dense(...., name = &quot;y&quot;)
    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
    return model

pipeline = Pipeline(feature_name=[&quot;x&quot;, &quot;y&quot;],
                    ...)

network = Network(model=my_network(),
                  ...)
</code></pre></div><h2 id="loss"><a href="#loss" aria-hidden="true" class="header-anchor">#</a> Loss</h2> <p>All standard <code>tf.keras</code> loss functions are supported, in this case, you
can simply provide the name of the loss as a string. Please refer
official
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses" target="_blank" rel="noopener noreferrer">Losses<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> for
a complete list of <code>tf.keras</code> loss functions.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>network = Network(...,
                  loss=&quot;categorical_crossentropy&quot;,
                  ...)
</code></pre></div><p>User can also define customized loss by tensorflow.keras:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>import tensorflow.keras.backend as K

def rmse_loss(y_true, y_pred):
    rmse = K.sqrt(K.mean(K.square(y_true - y_pred)))
    return rmse

network = Network(...,
                  loss=rmse_loss,
                  ...)
</code></pre></div><h2 id="metrics"><a href="#metrics" aria-hidden="true" class="header-anchor">#</a> Metrics</h2> <p>Metrics also work similarly to loss. For standard Keras metrics (e.g.,
accuracy), you can simply specify the name of metric(s) in a list.
Please refer official
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics" target="_blank" rel="noopener noreferrer">Metrics<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
for a complete list of metric functions.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>network = Network(...,
                  metrics=[&quot;acc&quot;],
                  ...)
</code></pre></div><p>User can also define customized metrics by tensorflow.keras:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K

<span class="token keyword">def</span> <span class="token function">dice</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    intersection <span class="token operator">=</span> K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_true <span class="token operator">*</span> y_pred<span class="token punctuation">)</span>
    coef <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span> <span class="token operator">*</span> intersection <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_true<span class="token punctuation">)</span> <span class="token operator">+</span> K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> coef

network <span class="token operator">=</span> Network<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
                metrics<span class="token operator">=</span><span class="token punctuation">[</span>dice<span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="optimizer"><a href="#optimizer" aria-hidden="true" class="header-anchor">#</a> Optimizer</h2> <p>FastEstimator is compatible with optimizers from <code>tf.keras.optimizer</code>,
please refer to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers" target="_blank" rel="noopener noreferrer">Optimizers<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
for a compelete list of optimizers. One can simply use string with
default optimizer settings:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>network = Network(...,
                  optimizer=&quot;adam&quot;,
                  ...)
</code></pre></div><p>Users can also pass an optimizer instance with custom settings:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>network = Network(...,
                  optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.95),
                  ...)
</code></pre></div><h2 id="model-save-path"><a href="#model-save-path" aria-hidden="true" class="header-anchor">#</a> Model Save Path</h2> <p>In FastEstimator, model artifacts will be saved in a random path in
[/tmp]{.title-ref} by default. If user wants to save model to a specific
directory, simply pass the directory to the <code>model_dir</code>: Once network
instance is created, user can access the saving path by
<code>network.model_dir</code>.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>network = Network(...,
                  model_dir=&quot;/home/model&quot;,
                  ...)
</code></pre></div><h1 id="estimator"><a href="#estimator" aria-hidden="true" class="header-anchor">#</a> Estimator</h1> <p>In FastEstimator, the [Estimator]{.title-ref} stores information about
the optimization process. It takes both [pipeline]{.title-ref} and
[network]{.title-ref} as input, configures them properly for different
training settings. Next, we show several places where user can customize
the training loop.</p> <h2 id="callbacks"><a href="#callbacks" aria-hidden="true" class="header-anchor">#</a> Callbacks</h2> <p>Users can use all callbacks in <code>tf.keras.callbacks</code> except for three:</p> <ul><li>`LearningRateScheduler`: Use
<code>fastestimator.estimator.callbacks.LearningRateScheduler</code></li> <li>`ReduceLROnPlateau`: Use
<code>fastestimator.estimator.callbacks.ReduceLROnPlateau</code></li> <li>`EarlyStopping`: Use
<code>fastestimator.estimator.callbacks.EarlyStopping</code></li></ul> <p>For other callbacks, please refer to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks" target="_blank" rel="noopener noreferrer">Callbacks<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
in Tensorflow Keras. Next, we present an example of using callbacks in
FastEstimator:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.estimator.callbacks import LearningRateScheduler, EarlyStopping
from fastestimator.network.lrscheduler import CyclicScheduler
from fastestimator.estimator.estimator import Estimator
from tensorflow.keras.callbacks import TensorBoard

callbacks = [LearningRateScheduler(schedule=CyclicScheduler()),
             EarlyStopping(patience=3),
             TensorBoard()]

estimator = Estimator(...,
                      callbacks=callbacks,
                      ...)
</code></pre></div><h2 id="custom-steps"><a href="#custom-steps" aria-hidden="true" class="header-anchor">#</a> Custom Steps</h2> <p>By default, the number of training steps and validation steps for each
epoch is calculated as:</p> <ul><li>steps_per_epoch = num_examples / batch_size / num_process</li> <li>validation_steps = num_examples / batch_size</li></ul> <p>where [num_process]{.title-ref} is the number of parallel training
processes, in multi-GPU training, it is the number of GPUs. User can
override the number of training and validation steps in the Estimator:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>estimator = Estimator(...,
                      steps_per_epoch=100,
                      validation_steps=100,
                      ...)
</code></pre></div><h2 id="logging-configuration"><a href="#logging-configuration" aria-hidden="true" class="header-anchor">#</a> Logging Configuration</h2> <p>During trainig, the training logs will appear every 100 steps as
default, users can change the logging interval through <code>log_steps</code>
argument, for example, if we want the log to appear every 10 steps:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>estimator = Estimator(...,
                      log_steps=10,
                      ...)
</code></pre></div><p>The training speed may decrease if the logging interval is too small.</p> <h1 id="other-utility-functions"><a href="#other-utility-functions" aria-hidden="true" class="header-anchor">#</a> Other Utility Functions</h1> <p>Outside of core API, FastEstimator offers some useful utilify functions
that can be used independently.</p> <h2 id="tfrecorder"><a href="#tfrecorder" aria-hidden="true" class="header-anchor">#</a> TFRecorder</h2> <p><code>fastestimator.util.tfrecord.TFRecorder</code> can help you easily create
tfrecord from any data. The usage of TFRecorder is very similar to
<code>Pipeline</code>:</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.pipeline.dynamic.preprocess import Resize, Minmax
from fastestimator.util.tfrecord import TFRecorder
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

tfrecorder = TFRecorder(feature_name=[&quot;x&quot;, &quot;y&quot;],
                        train_data={&quot;x&quot;: x_train, &quot;y&quot;: y_train},
                        validation_data = 0.2,
                        transform_dataset=[[Resize([50,50]), Minmax()], 
                                            []])
tfrecorder.create_tfrecord(save_dir=&quot;/home/data&quot;)
</code></pre></div><h2 id="add-summary"><a href="#add-summary" aria-hidden="true" class="header-anchor">#</a> add_summary</h2> <p>While creating tfrecords, both TFRecorder or FastEstimator produce a
summary file that is required for training. If you have previously built
tfrecords outside of FastEstimator or TFRecorder, you can use
<code>add_summary</code> to create the summary file for training.</p> <div class="language-{.sourceCode .python} extra-class"><pre class="language-text"><code>from fastestimator.util.tfrecord import add_summary, get_features

# First, get feature name and related information
print(get_features(&quot;/data/data/Xray/chestfrontal/chestfrontal_train_0000.tfrecords&quot;))

# Next, fill in the required field
add_summary(data_dir=&quot;/data/data/Xray/chestfrontal&quot;, 
            train_prefix=&quot;chestfrontal_train&quot;, 
            eval_prefix= &quot;chestfrontal_val&quot;, 
            feature_name=[&quot;image_raw&quot;, &quot;image_labels&quot;], 
            feature_dtype=[&quot;uint8&quot;, &quot;int64&quot;])
</code></pre></div><h1 id="full-code-demo"><a href="#full-code-demo" aria-hidden="true" class="header-anchor">#</a> Full Code Demo</h1> <ul><li>Image Classification:
<a href="https://github.build.ge.com/edisonaitk/public_model/blob/master/classification_mnist/mnist.ipynb" target="_blank" rel="noopener noreferrer">Mnist-Classification<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Image Segmentation:
<a href="https://github.build.ge.com/edisonaitk/public_model/blob/master/segmentation_cub200/cub200.ipynb" target="_blank" rel="noopener noreferrer">Cub200-Segmentation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Natural Language Processing:
<a href="https://github.build.ge.com/edisonaitk/public_model/blob/master/sentiment_classification_imdb/imdb.ipynb" target="_blank" rel="noopener noreferrer">IMDB-Review<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.5136acb6.js" defer></script><script src="/assets/js/2.6ec3d9bf.js" defer></script><script src="/assets/js/7.85ca8dce.js" defer></script>
  </body>
</html>
